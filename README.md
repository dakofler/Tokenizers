# Tokenizers

Tokenizers is a collection of tokenization implementations focused on transparency and readability.

## Installation

You can install Tokenizers directly from GitHub.
```bash
pip install git+https://github.com/dakofler/Tokenizers.git
```

## Usage

There are example-notebooks included that show how to use the package, see [Examples](https://github.com/dakofler/Tokenizers/tree/main/examples).

## Author
Daniel Kofler - AI Research Associate ([dkofler@outlook.com](mailto:dkofler@outlook.com))

## License
[MIT](https://choosealicense.com/licenses/mit/)


Cheers,<br>
Daniel